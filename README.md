# Project Title: Enhancing ML Performance Through Class Imbalance Solutions
## Developed By:    Mohammad Kamil (29464)     - SMCS
### In this project, I have implemented various class imbalance techniques on different imbalanced datasets from Kaggle and compared the performance of each technique. Initially, I ran baseline executions before applying these techniques and then evaluated the results after application. I ahve also applied different features selection techniques including filter methods,wrapper methods and PCA and other necessary things like EDA etc.
## The classification models used in this project include:
- KNN
- Naive Bayes
- Decision Tree
- Logistic Regression
- SVM

#### I compared the model performance using confusion matrices and classification reports. The conclusion for each technique on different datasets is documented in individual notebooks.
## Class Imbalance Techniques used in this project include:
I have used following class imbalacne techniques in this project:
- Ensemble Methods and Weights
- Clustering-based Oversampling
- Oversampling with SMOTE (Synthetic Minority Over-sampling Technique)

## Selected Dataset from Kaggle
I have select following imbalance dataset from Kaggle:
- Cerebral Stroke Prediction-Imbalanced Dataset (https://www.kaggle.com/datasets/shashwatwork/cerebral-stroke-predictionimbalaced-dataset)
- IT Customer Chrun (https://www.kaggle.com/datasets/soheiltehranipour/it-customer-churn/)
- Credit-card-Fraud Detection-Imbalanced-Dataset (https://www.kaggle.com/datasets/dark06thunder/credit-card-dataset)
